{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "import cv2\n",
    "from BoundingBox import BoundingBox\n",
    "from BoundingBoxes import BoundingBoxes\n",
    "from Evaluator import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    gt_path = args.gt_path\n",
    "    pred_path = args.pred_path\n",
    "    iou_ts = args.iou_ts\n",
    "    output_file = args.output_path\n",
    "\n",
    "\n",
    "\n",
    "    if type(iou_ts) == float:\n",
    "        iou_ts = [iou_ts]\n",
    "    else:\n",
    "        iou_ts = [float(i) for i in iou_ts.split()]\n",
    "\n",
    "    with open(gt_path) as json_file:\n",
    "        gt_data = json.load(json_file)\n",
    "\n",
    "    with open(pred_path) as json_file:\n",
    "        res_data = json.load(json_file)\n",
    "\n",
    "    all_bboxes = BoundingBoxes()\n",
    "\n",
    "    img2size = {}\n",
    "\n",
    "    for image in gt_data['images']:\n",
    "        img2size[image['id']] = (image['height'], image['width'])\n",
    "\n",
    "    id2ctg = {}\n",
    "\n",
    "    for category in gt_data['categories']:\n",
    "        id2ctg[category['id']] = category['name'] \n",
    "\n",
    "    for gt_idx, gt_obj in enumerate(gt_data['annotations']):\n",
    "\n",
    "        img_id = gt_obj['image_id']\n",
    "        gt_bbox = gt_obj['bbox']\n",
    "        category_id = gt_obj['category_id']\n",
    "\n",
    "        x, y, w, h = gt_bbox\n",
    "\n",
    "        gt_boundingBox = BoundingBox(imageName=str(img_id), classId=id2ctg[category_id], x=x, y=y, \n",
    "                                   w=w, h=h, typeCoordinates=CoordinatesType.Absolute,\n",
    "                                   bbType=BBType.GroundTruth, format=BBFormat.XYWH, imgSize=img2size[img_id])\n",
    "\n",
    "        all_bboxes.addBoundingBox(gt_boundingBox)\n",
    "\n",
    "    for detected_idx, detected_obj in enumerate(res_data):\n",
    "\n",
    "        img_id = detected_obj['image_id']\n",
    "        detected_bbox = detected_obj['bbox']\n",
    "        category_id = detected_obj['category_id']\n",
    "        score = detected_obj['score']\n",
    "\n",
    "        x, y, w, h = detected_bbox\n",
    "\n",
    "        gt_boundingBox = BoundingBox(imageName=str(img_id), classId=id2ctg[category_id],classConfidence=score, x=x, y=y, \n",
    "                                   w=w, h=h, typeCoordinates=CoordinatesType.Absolute,\n",
    "                                   bbType=BBType.Detected, format=BBFormat.XYWH, imgSize=img2size[img_id])\n",
    "\n",
    "        all_bboxes.addBoundingBox(gt_boundingBox)\n",
    "\n",
    "    evaluator = Evaluator()\n",
    "\n",
    "    mAR = 0\n",
    "\n",
    "    full_iouts = np.arange(0.5, 1., 0.05)\n",
    "\n",
    "    mAR = 0\n",
    "    mAP_over = 0\n",
    "\n",
    "    for iou in full_iouts:\n",
    "        recalls = []\n",
    "        maps = []\n",
    "\n",
    "        metricsPerClass = evaluator.GetPascalVOCMetrics(\n",
    "        all_bboxes,  # Object containing all bounding boxes (ground truths and detections)\n",
    "        IOUThreshold=iou,  # IOU threshold\n",
    "        method=MethodAveragePrecision.EveryPointInterpolation)\n",
    "\n",
    "        for mc in metricsPerClass:\n",
    "            try:\n",
    "                recalls.append(mc['recall'][-1])\n",
    "            except:\n",
    "                recalls.append(0)\n",
    "            maps.append(mc['AP'])\n",
    "\n",
    "        mAR += np.array(recalls).mean()\n",
    "        mAP_over += np.array(maps).mean()\n",
    "\n",
    "    mAR /= len(full_iouts)\n",
    "    mAP_over /= len(full_iouts)\n",
    "    \n",
    "    row_list = []\n",
    "    \n",
    "    row_list.append({'classes':'mAP over iou=[.5-.95]', 'iou_t':f'{mAP_over}'})\n",
    "    row_list.append({'classes':'mAR', 'iou_t':f'{mAR}'})\n",
    "    row_list.append({})\n",
    "    \n",
    "    for iou_t in iou_ts:\n",
    "        \n",
    "        metricsPerClass = evaluator.GetPascalVOCMetrics(\n",
    "            all_bboxes,  # Object containing all bounding boxes (ground truths and detections)\n",
    "            IOUThreshold=iou_t,  # IOU threshold\n",
    "            method=MethodAveragePrecision.EveryPointInterpolation)\n",
    "\n",
    "        average_precisions = []\n",
    "        true_positives = []\n",
    "        total_positives = []\n",
    "        false_positives = []\n",
    "\n",
    "        for mc in metricsPerClass:\n",
    "            \n",
    "            class_dict = {}\n",
    "            \n",
    "            class_dict['iou_t'] = iou_t\n",
    "            \n",
    "            # Get metric values per each class\n",
    "            c = mc['class']\n",
    "            class_dict['classes'] = c\n",
    "            \n",
    "            precision = mc['precision']\n",
    "            recall = mc['recall']\n",
    "            average_precision = mc['AP']\n",
    "            class_dict['AP'] = average_precision\n",
    "            \n",
    "            ipre = mc['interpolated precision']\n",
    "            irec = mc['interpolated recall']\n",
    "\n",
    "            # Print AP per class\n",
    "            total_p = mc['total positives']\n",
    "            TP = mc['total TP']\n",
    "            FP = mc['total FP']\n",
    "\n",
    "            average_precisions.append(average_precision)\n",
    "            true_positives.append(TP)\n",
    "            total_positives.append(total_p)\n",
    "            false_positives.append(FP)\n",
    "\n",
    "            class_dict['ACC'] = TP/(FP+total_p)\n",
    "            class_dict['TP'] = TP\n",
    "            class_dict['FP'] = FP\n",
    "            class_dict['total_P'] = total_p\n",
    "            \n",
    "            if TP+FP>0:\n",
    "                class_dict['Pr'] = TP/(TP+FP)\n",
    "            else:\n",
    "                class_dict['Pr'] = 0\n",
    "                \n",
    "            class_dict['Re'] = TP/total_p\n",
    "            \n",
    "            row_list.append(class_dict)\n",
    "        \n",
    "        row_list.append({'classes':'mAP', 'iou_t':iou_t, 'AP':np.array(average_precisions).mean()})\n",
    "        row_list.append({'classes':'Mean ACC', 'iou_t':iou_t, 'AP':np.array(true_positives).sum() / (np.array(total_positives).sum() + np.array(false_positives).sum())})\n",
    "        row_list.append({})\n",
    "        \n",
    "    res_df = pd.DataFrame(row_list[:-1], columns=['classes', 'iou_t', 'AP', 'ACC', 'TP', 'FP', 'total_P', 'Re', 'Pr'])\n",
    "    \n",
    "    res_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-output_path'], dest='output_path', nargs=None, const=None, default='output.txt', type=<class 'str'>, choices=None, help='Path to the file with the results', metavar='')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Пример ввода:\n",
    "python model_detection_eval.py -gt_path val_small_40_classes.json -pred_path coco_instances_results.json -output_path output3.txt -t \"0.5 0.6 0.9\"\n",
    "\"\"\"\n",
    "\n",
    "parser = argparse.ArgumentParser(prog='Object Detection Metrics', description=\"some metrics\")\n",
    "parser.add_argument(\n",
    "        '-t',\n",
    "        '--threshold',\n",
    "        dest='iou_ts',\n",
    "        default=0.5,\n",
    "        metavar='',\n",
    "        help='IOU threshold. Default 0.5. If you want to use several values of IOU write them in a string space-separated (ex.: \"0.5 0.6\")')\n",
    "\n",
    "parser.add_argument(\n",
    "        '-gt_path',\n",
    "        dest='gt_path',\n",
    "        type=str,\n",
    "        metavar='',\n",
    "        required=True,\n",
    "        help='Path to the file with Ground Truth bboxes')\n",
    "\n",
    "parser.add_argument(\n",
    "        '-pred_path',\n",
    "        dest='pred_path',\n",
    "        type=str,\n",
    "        metavar='',\n",
    "        required=True,\n",
    "        help='Path to the file with predicted bboxes')\n",
    "\n",
    "parser.add_argument(\n",
    "    '-output_path',\n",
    "        dest='output_path',\n",
    "        type=str,\n",
    "        default='output.csv',\n",
    "        metavar='',\n",
    "        help='Path to the file with the results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(['--'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
